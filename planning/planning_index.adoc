// vim: set syntax=asciidoc:
[[plan]]
== Application Planning
:data-uri:
:homepage https://github.com/projectatomic/container-best-practices:

As you begin to contemplate the containerization of your application, there are number of factors that
should be considered prior to authoring a Dockerfile.  You will want to plan out everything from
how to start the application, to network considerations, to making sure your image is architected in a way that
can run in multiple environments like Atomic Host or OpenShift.

The following sections discuss our advice and best practices on planning to containerize your applications.


=== Application Classes

We have defined applications into four general categories:

. System Services
. Client Tools
. Service Components
. Micro-service Applications


==== System Services

System services are a special kind of application. These are drivers or system agents
that extend the functionality of the host system. They are typically single-container
images. They are typically run using automation during a start-up script like cloud-init or a
configuration management system. System service containers require special runtime configuration to
enable the appropriate level of privilege to modify the host system. They are commonly referred as
Super Privileged Containers (SPCs). They utilize the benefits of container packaging but not separation.

==== Client Tools

Client Tools applications are another special kind of application. These are used by end-users who do
not wish to install a client using traditional packaging such as RPM. Container technology enables an
end-user to add a client to their workstation without modifying the operating system.

There are an endless number of potential clients for this class of applications. A few examples include
remote clients such as OpenStack or Amazon Web Services (AWS) client tools. An extension of the model is
vagrant-like development environment where a tool set for a given project is packaged. For example,
Red Hat's link:https://access.redhat.com/documentation/en/red-hat-enterprise-linux-atomic-host/version-7/getting-started-with-containers/#using_the_atomic_tools_container_image[rhel-tools image]
is a toolkit for interacting with an immutable Atomic host system. It includes git, strace and sosreport, for example.

Two important architectural decisions should be considered for client container images.

. How does the end-user interact with the container? Will they use them like traditional command line
interface (CLI) tools? Or will they enter the container environment as a shell, perform some commands, then exit.
The entrypoint command chosen for the container will determine the default behavior.
. Will end-users will need access to files on the host system? If so, will the default behavior bindmount
the current working directory or a user-specified directory?

==== Service Components

Service components are applications that an application developer integrates with. Databases are common examples.
A database is typically a component of a larger application.

The challenge of porting service components to container technology is optimizing integration. Will the application
developer be able to configure the service to their needs? Will the application developer have sufficient documentation
to install, configure and secure the service being integrated?

==== Microservice Applications

The microservice architecture is particularly well-suited to container technology. Martin Fowler describes microservice
applications as "suites of independently deployable services."footnote:[Martin Fowler,
http://martinfowler.com/articles/microservices.html] Well-designed microservice applications have a clean separation
of code, configuration and data.

Planning is especially critical for microservice applications because they are especially challenging to port to
container technology. The planning phase must include experts who understand the application's architecture and
service topology, performance characteristics, configuration and dependencies such as networking and storage. While
many applications can be ported to container technology without modification there are sometimes optimizations that
should be made regarding configuration, storage, installation or service architecture.

===== Deconstructing Microservice Applications

The process of deconstructing applications varies widely depending on the complexity and architecture of the
application. Consider the following steps as a guide to a generalized process.

. Identify the components that will be broken down into microservices. These typically map to a container images.
. Identify how the services will communicate. How are REST or message bus interfaces authenticated?
. Identify how data will be accessed by the services. Which services need read/write access to the storage?
. Create a service topology drawing to represent the components, lines of communication and storage. This will
guide the development work, configuration discussions, debugging and potentially become part of the
end-user documentation.
. Identify how the services will be configured, which services need to share configuration and how these
services might be deployed in a highly available configuration.


==== Security and user requirements

==== Host and image synchronization

Some applications that run in containers require the host and container to more or less be synchronized on certain
attributes so their behaviors are also similar.  One such common attribute can be time.  The following sections discuss
best practices to keeping those attributes similar or the same.

===== Time

Consider a case where multiple containers (and the host) are running applications and logging to something like
a log server.  The log timestamps and information would almost be entirely useless if each container reported a different
time than the host.

The best way to synchronize the time between a container and its host is through the use of bind mounts.  You simply need
to bind mount the hosts _/etc/localtime_ with the container's _/etc/localtime_.

In your Dockerfile, this can be accomplished by adding the following to your RUN label.

.Synchronizing the timezone of the host to the container.
```
-v /etc/localtime:/etc/localtime
```

===== Machine ID

The _etc/machine_id_ file is often used as an identifier for things like applications and logging.  Depending on your
application, it might be beneficial to also bind mount the machine id of the host into the container.  For example.
in many cases journald relies on the machine ID for identification.  The sosreport application also uses it.  To bind
mount the machine ID of the host to the container, add something like the following to your RUN label.

.Synchronizing the host machine ID with a container
```
-v /etc/machine_id:/etc/machine_id
```

=== Considerations for images on Atomic Host and OpenShift

=== Where to store related components

==== scripts

==== tar files

==== help files

==== Dockerfiles

[[planning_starting_application]]
=== Starting your applications within a container
At some point in the design of your Dockerfile and image, you will need to determine how to start your
application.  There are three prevalent methods for starting applications:

- Call the application binary directly
- Call a script that results in your binary starting
- Use systemd to start the application

For the most part, there is no single right answer on which method should be used; however, there are
some softer decision points that might help you decide which would be easiest for you as the
Dockerfile owner.

==== Calling the binary directly
If your application is not service oriented, calling the binary directly might be the simplest and most
straight-forward method to start a container.  There is no memory overhead and no additional packages
are needed (like systemd and its dependancies).  However, it is more difficult to deal with
setting environment variables.

==== Using a script
Using a special script to start your application in a container can be a handy way to deal with slightly
more complex applications.  One upside is that it is generally trivial to set environment variables.  This
method is also good when you need to call more than a single binary to start the application correctly.
One downside is that you now have to maintain the script and ensure it is always present in the image.

==== Use systemd
Using systemd to start your application is a great if your application is service oriented (like httpd).
It can benefit from leveraging well tested unit files generally delivered with the applications
themselves and therefor can make complex applications that require environment variables easy to work
with.  One disadvantage is that systemd will increase the size of your image and there is a small
amount of memory used for systemd itself.

NOTE: As docker-1.10, the docker run parameter of _--privileged_ is no longer needed to use systemd
within a container.


=== Network Considerations

==== single host

==== multi-host

==== AEP / OSE / Docker considerations

=== Storage Considerations
==== Persistent vs ephemeral storage
==== Docker persistent storage
==== OpenShift persistent storage

=== Security and User considerations

==== Passing credentials and secrets
==== User NameSpace Mapping (docker-1.10 feature)
==== https://www.openshift.com/promotions/docker-security.html

=== Image naming
https://github.com/projectatomic/ContainerApplicationGenericLabels/blob/master/vendor/redhat/names.md

=== Deployment Considerations

Preparing applications for production distribution and deployment must carefully consider the supported
deployment platforms. Production services require high uptime, injection of private or sensitive data,
storage integration and configuration control. The deployment platform determines methods for load balancing,
scheduling and upgrading. A platform that does not provide these services requires additional work when
developing the container packaging.

==== Platform
==== Lifecycle
==== Maintenance
==== Build infrastructure